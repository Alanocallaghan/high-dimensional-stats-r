---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 02-high-dimensional-regression_b.md in _episodes_rmd/
title: "Stepwise feature selection for regression"
teaching: 0
exercises: 0
questions:
- "Why would we want to find a subset of features
  that are associated with an outcome?"
- "How can we iteratively find a good subset of our features
  variables to use for regression?"
- "What are some risks and downsides of iterative feature
  selection?"
objectives:
- "Understand multiple regression in a biomedical context."
- "Understand how to fit a stepwise regression model."
keypoints:
- "Sets of features can be more predictive and provide
  a better explanation than a single feature alone."
- "Stepwise regression allows us to find a set of features that
  are associated with an outcome (eg, age)."
- "Stepwise regression will tend to retain only one
  feature out of many that are correlated."
- "Stepwise regression is not very efficient."
math: yes
---





In the previous 

Another way of modelling these data is to model age as 

$$
    y_j = \beta_0 + \beta_1 X_1 + \dots \beta_p X_p + \epsilon_j
$$



~~~
suppressPackageStartupMessages({
    library("glmnet")
    library("limma")
    library("minfi")
    library("here")
    library("broom")
})

if (!file.exists(here("data/methylation.rds"))) {
    source(here("data/methylation.R"))
}
norm <- readRDS(here("data/methylation.rds"))

lim <- norm
y <- lim$Age
X <- getM(lim)
~~~
{: .language-r}

However when the number of predictors is greater than the number of samples
(basically always true in genetics) it isn't possible to include everything!

There are some techniques that you can use to find a set of predictors!

- screening (correlation etc): bad, don't do
- screening (variance): not necessarily bad if the screening variable is sensible
- forward/reverse/best subset selection


~~~
if (!file.exists(here("data/synthetic.rds"))) {
    source(here("data/synthetic.R"))
}
synthetic <- readRDS(here("data/synthetic.rds"))
~~~
{: .language-r}





~~~
X <- assay(synthetic)
y <- synthetic$age
beta <- rowData(synthetic)$true_beta
names(beta) <- rownames(synthetic)
## challenge 3: fit y on x univariate
## compare with true betas
cc <- sapply(seq_len(nrow(X)), function(i) {
    coef(lm(y ~ X[i, ]))[[2]]
})
plot(cc, beta, pch = 19, cex = 0.5)
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-4-1.png" title="plot of chunk unnamed-chunk-4" alt="plot of chunk unnamed-chunk-4" width="612" style="display: block; margin: auto;" />




> ## Exercise
> Perform forward subset selection on the methylation data.
> 
> 
> > ## Solution
> > 
> > 
> {: .solution}
{: .challenge}




~~~
## challenge 4: forward selection
## compare with true betas
xy <- as.data.frame(cbind(t(X), y = y))
int <- lm(y ~ 1, data = xy)
all <- lm(y ~ . + 0, data = xy)
forward <- step(
    int,
    scope = list(upper = formula(all), lower = formula(int)),
    direction = "forward",
    trace = 0
)
forward$anova
~~~
{: .language-r}



~~~
           Step Df    Deviance Resid. Df  Resid. Dev          AIC
1               NA          NA        99 4205.310000  375.8933105
2  + feature_25 -1 778.8659419        98 3426.444058  357.4108099
3  + feature_35 -1 627.3171571        97 2799.126901  339.1892640
4  + feature_75 -1 473.6315230        96 2325.495378  322.6518175
5  + feature_38 -1 395.6505038        95 1929.844874  306.0024717
6  + feature_12 -1 328.2372213        94 1601.607653  289.3593001
7  + feature_40 -1 376.2359433        93 1225.371710  264.5829327
8  + feature_42 -1 323.6199303        92  901.751779  235.9169107
9  + feature_76 -1 224.7641323        91  676.987647  209.2482840
10 + feature_33 -1  85.8639008        90  591.123746  197.6855194
11 + feature_21 -1  92.0139472        89  499.109799  182.7655923
12 + feature_98 -1  85.9096742        88  413.200125  165.8761853
13 + feature_13 -1  64.8293344        87  348.370790  150.8097216
14  + feature_8 -1  69.7767552        86  278.594035  130.4585465
15 + feature_88 -1  64.9659920        85  213.628043  105.9066200
16 + feature_32 -1  37.5518714        84  176.076172   88.5746509
17 + feature_81 -1  28.5502915        83  147.525880   72.8833433
18 + feature_85 -1  23.9961545        82  123.529726   57.1311635
19 + feature_96 -1  12.6151852        81  110.914541   48.3589814
20 + feature_31 -1  10.4361772        80  100.478363   40.4772227
21 + feature_16 -1  12.2141078        79   88.264255   29.5165032
22  + feature_9 -1   9.1548752        78   79.109380   20.5661269
23 + feature_72 -1  12.2203329        77   66.889047    5.7865051
24 + feature_37 -1   5.3009989        76   61.588048   -0.4702354
25 + feature_30 -1   7.6325854        75   53.955463  -11.7011239
26 + feature_91 -1   4.3889814        74   49.566482  -18.1855354
27 + feature_87 -1   3.6321137        73   45.934368  -23.7956592
28 + feature_64 -1   2.5479318        72   43.386436  -27.5023324
29 + feature_51 -1   2.3347031        71   41.051733  -31.0337131
30 + feature_67 -1   2.3167792        70   38.734954  -34.8427793
31 + feature_60 -1   1.9635213        69   36.771433  -38.0448931
32 + feature_10 -1   2.0359329        68   34.735500  -41.7407977
33 + feature_89 -1   2.2957263        67   32.439773  -46.5784944
34 + feature_39 -1   1.6995485        66   30.740225  -49.9598132
35 + feature_73 -1   1.8464962        65   28.893729  -54.1545615
36 + feature_29 -1   1.5378757        64   27.355853  -57.6239677
37 + feature_71 -1   1.1472518        63   26.208601  -59.9082540
38 + feature_50 -1   1.2273991        62   24.981202  -62.7046559
39 + feature_82 -1   1.0709791        61   23.910223  -65.0864078
40 + feature_20 -1   1.2430518        60   22.667171  -68.4252513
41  + feature_4 -1   1.1235631        59   21.543608  -71.5091023
42 + feature_41 -1   0.8156720        58   20.727936  -73.3687827
43 + feature_70 -1   0.9245741        57   19.803362  -75.9318466
44 + feature_77 -1   1.0046443        56   18.798718  -79.1381527
45 + feature_28 -1   1.0326967        55   17.766021  -82.7882485
46 + feature_93 -1   0.6515045        54   17.114517  -84.5243163
47 + feature_14 -1   0.5410607        53   16.573456  -85.7367819
48 + feature_78 -1   0.7539021        52   15.819554  -88.3923436
49  + feature_7 -1   0.8275429        51   14.992011  -91.7652742
50 + feature_83 -1   1.4052390        50   13.586772  -99.6073534
51  + feature_6 -1   0.8753680        49   12.711404 -104.2670665
52 + feature_94 -1   0.7669785        48   11.944425 -108.4905525
53 + feature_23 -1   0.4847408        47   11.459684 -110.6335016
54 + feature_84 -1   0.7859147        46   10.673770 -115.7380889
55 + feature_56 -1   0.4139047        45   10.259865 -117.6930507
56  + feature_1 -1   0.4167579        44    9.843107 -119.8398769
57 + feature_22 -1   0.4298871        43    9.413220 -122.3055110
58 + feature_92 -1   0.3291967        42    9.084023 -123.8653010
59 + feature_97 -1   0.4451213        41    8.638902 -126.8894706
60 + feature_45 -1   0.2585798        40    8.380322 -127.9283836
61 + feature_48 -1   0.2597206        39    8.120602 -129.0765953
62 + feature_19 -1   0.3560503        38    7.764551 -131.5601521
63 + feature_68 -1   0.3371474        37    7.427404 -133.9993799
64 + feature_27 -1   0.2219795        36    7.205424 -135.0336053
65 + feature_86 -1   0.1879532        35    7.017471 -135.6767258
66 + feature_65 -1   0.2610835        34    6.756388 -137.4681802
67 + feature_66 -1   0.3004170        33    6.455971 -140.0164794
68 + feature_90 -1   0.2427597        32    6.213211 -141.8492357
69 + feature_46 -1   0.2473353        31    5.965876 -143.9114339
70 + feature_95 -1   0.1693910        30    5.796485 -144.7918538
71 + feature_80 -1   0.2562713        29    5.540213 -147.3137173
72 + feature_74 -1   0.1896066        28    5.350607 -148.7960220
73 + feature_55 -1   0.1810056        27    5.169601 -150.2374652
74 + feature_69 -1   0.2253045        26    4.944297 -152.6935470
75 + feature_54 -1   0.2079871        25    4.736310 -154.9911927
76 + feature_52 -1   0.1496850        24    4.586625 -156.2025814
~~~
{: .output}



~~~
plot(coef(forward), beta[names(coef(forward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-5-1.png" title="plot of chunk unnamed-chunk-5" alt="plot of chunk unnamed-chunk-5" width="612" style="display: block; margin: auto;" />


~~~
## note about backward/both, not a challenge
all <- lm(y ~ . + 0, data = xy)
backward <- step(
    all,
    scope = formula(all),
    direction = "backward",
    trace = 0
)
backward$anova
~~~
{: .language-r}



~~~
          Step Df     Deviance Resid. Df Resid. Dev       AIC
1              NA           NA         1   1.842798 -201.3885
2 - feature_23  1 0.0005905246         2   1.843388 -203.3565
3 - feature_62  1 0.0117233857         3   1.855112 -204.7225
4 - feature_45  1 0.0083927814         4   1.863504 -206.2711
5 - feature_28  1 0.0339764942         5   1.897481 -206.4643
6 - feature_15  1 0.0148933282         6   1.912374 -207.6825
7 - feature_57  1 0.0377078510         7   1.950082 -207.7299
~~~
{: .output}



~~~
plot(coef(backward), beta[names(coef(backward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-6-1.png" title="plot of chunk unnamed-chunk-6" alt="plot of chunk unnamed-chunk-6" width="612" style="display: block; margin: auto;" />


{% include links.md %}
