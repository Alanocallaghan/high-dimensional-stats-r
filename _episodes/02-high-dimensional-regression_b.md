---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 02-high-dimensional-regression_b.md in _episodes_rmd/
title: "Stepwise feature selection for regression"
teaching: 0
exercises: 0
questions:
- "Why would we want to find a subset of features
  that are associated with an outcome?"
- "How can we iteratively find a good subset of our features
  variables to use for regression?"
- "What are some risks and downsides of iterative feature
  selection?"
objectives:
- "Understand multiple regression in a biomedical context."
- "Understand how to fit a stepwise regression model."
keypoints:
- "Sets of features can be more predictive and provide
  a better explanation than a single feature alone."
- "Stepwise regression allows us to find a set of features that
  are associated with an outcome (eg, age)."
- "Stepwise regression will tend to retain only one
  feature out of many that are correlated."
- "Stepwise regression is not very efficient."
math: yes
---





In the previous 

Another way of modelling these data is to model age as 

$$
    y_j = \beta_0 + \beta_1 X_1 + \dots \beta_p X_p + \epsilon_j
$$



~~~
suppressPackageStartupMessages({
    library("glmnet")
    library("limma")
    library("minfi")
    library("here")
    library("broom")
})

if (!file.exists(here("data/methylation.rds"))) {
    source(here("data/methylation.R"))
}
norm <- readRDS(here("data/methylation.rds"))

lim <- norm
y <- lim$Age
X <- getM(lim)
~~~
{: .language-r}

However when the number of predictors is greater than the number of samples
(basically always true in genetics) it isn't possible to include everything!

There are some techniques that you can use to find a set of predictors!

- screening (correlation etc): bad, don't do
- screening (variance): not necessarily bad if the screening variable is sensible
- forward/reverse/best subset selection


~~~
if (!file.exists(here("data/synthetic.rds"))) {
    source(here("data/synthetic.R"))
}
synthetic <- readRDS(here("data/synthetic.rds"))
~~~
{: .language-r}





~~~
X <- assay(synthetic)
y <- synthetic$age
beta <- rowData(synthetic)$true_beta
names(beta) <- rownames(synthetic)
## challenge 3: fit y on x univariate
## compare with true betas
cc <- sapply(seq_len(nrow(X)), function(i) {
    coef(lm(y ~ X[i, ]))[[2]]
})
plot(cc, beta, pch = 19, cex = 0.5)
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-4-1.png" title="plot of chunk unnamed-chunk-4" alt="plot of chunk unnamed-chunk-4" width="612" style="display: block; margin: auto;" />




> ## Exercise
> Perform forward subset selection on the methylation data.
> 
> 
> > ## Solution
> > 
> > 
> {: .solution}
{: .challenge}




~~~
## challenge 4: forward selection
## compare with true betas
xy <- as.data.frame(cbind(t(X), y = y))
int <- lm(y ~ 1, data = xy)
all <- lm(y ~ . + 0, data = xy)
forward <- step(
    int,
    scope = list(upper = formula(all), lower = formula(int)),
    direction = "forward",
    trace = 0
)
forward$anova
~~~
{: .language-r}



~~~
           Step Df    Deviance Resid. Df  Resid. Dev         AIC
1               NA          NA        99 3444.440000  355.934643
2  + feature_64 -1 654.3449663        98 2790.095034  336.866075
3   + feature_6 -1 501.1705978        97 2288.924436  319.066712
4  + feature_80 -1 334.5130159        96 1954.411420  305.267418
5  + feature_37 -1 371.5222209        95 1582.889199  286.183688
6  + feature_25 -1 225.7600438        94 1357.129155  272.795665
7  + feature_26 -1 160.5412603        93 1196.587895  262.205918
8  + feature_15 -1 155.7623546        92 1040.825540  250.259928
9  + feature_65 -1 170.7343141        91  870.091226  234.342788
10  + feature_7 -1 184.4992923        90  685.591934  212.511242
11 + feature_43 -1 164.1548781        89  521.437056  187.141838
12 + feature_89 -1 116.4362421        88  405.000814  163.871889
13 + feature_28 -1  47.8119323        87  357.188882  153.309454
14 + feature_46 -1  48.9245239        86  308.264358  140.578753
15 + feature_41 -1  46.1068262        85  262.157532  126.377540
16 + feature_66 -1  40.2878782        84  221.869653  111.691988
17 + feature_95 -1  48.2240564        83  173.645597   89.184624
18 + feature_32 -1  32.3279834        82  141.317614   70.583975
19 + feature_74 -1  26.4178073        81  114.899806   51.889031
20 + feature_50 -1  22.1529653        80   92.746841   32.470345
21 + feature_72 -1  12.3611094        79   80.385732   20.166651
22 + feature_16 -1  10.2631883        78   70.122543    8.507414
23  + feature_8 -1   4.8946651        77   65.227878    3.271677
24 + feature_86 -1   4.2896659        76   60.938212   -1.530975
25 + feature_40 -1   3.5294168        75   57.408795   -5.497266
26 + feature_85 -1   2.9330985        74   54.475697   -8.741551
27 + feature_18 -1   2.9089622        73   51.566735  -12.229340
28 + feature_79 -1   3.2016893        72   48.365045  -16.639283
29  + feature_1 -1   4.1531530        71   44.211892  -23.617637
30 + feature_51 -1   2.1620743        70   42.049818  -26.631512
31 + feature_82 -1   2.3635152        69   39.686303  -30.416407
32 + feature_91 -1   1.9246482        68   37.761655  -33.387602
33  + feature_9 -1   1.9617603        67   35.799894  -36.722524
34 + feature_31 -1   1.8231672        66   33.976727  -39.949439
35 + feature_84 -1   1.5839953        65   32.392732  -42.723611
36 + feature_63 -1   1.5191177        64   30.873614  -45.526828
37 + feature_48 -1   1.1051549        63   29.768459  -47.172076
38 + feature_19 -1   1.3963490        62   28.372110  -49.976355
39 + feature_70 -1   1.6773814        61   26.694729  -54.070406
40 + feature_77 -1   1.2404606        60   25.454268  -56.828674
41 + feature_27 -1   1.2628476        59   24.191421  -59.917213
42  + feature_2 -1   1.6541454        58   22.537275  -64.999956
43 + feature_97 -1   0.8031393        57   21.734136  -66.628607
44 + feature_96 -1   0.9721495        56   20.761987  -69.204644
45 + feature_78 -1   0.9276044        55   19.834382  -71.775328
46 + feature_13 -1   0.7458111        54   19.088571  -73.608040
47 + feature_20 -1   0.7818501        53   18.306721  -75.790193
48 + feature_88 -1   0.8232633        52   17.483458  -78.391503
49 + feature_61 -1   0.7044510        51   16.779007  -80.504168
50 + feature_56 -1   0.6872065        50   16.091800  -82.686035
51 + feature_69 -1   0.9095496        49   15.182251  -86.504316
52  + feature_4 -1   0.5487045        48   14.633546  -88.185361
53 + feature_94 -1   0.6656312        47   13.967915  -90.840728
54 + feature_36 -1   0.5560853        46   13.411830  -92.903306
55 + feature_29 -1   0.6044179        45   12.807412  -95.514614
56 + feature_92 -1   1.0136604        44   11.793751 -101.760034
57 + feature_22 -1   0.4755463        43   11.318205 -103.875769
58 + feature_57 -1   0.4598075        42   10.858398 -106.023144
59  + feature_3 -1   0.5123012        41   10.346096 -108.856090
60 + feature_87 -1   0.4926497        40    9.853447 -111.734888
61 + feature_23 -1   0.4558789        39    9.397568 -114.471927
62 + feature_83 -1   0.2893497        38    9.108218 -115.599309
63 + feature_24 -1   0.5566179        37    8.551600 -119.905176
64 + feature_33 -1   0.4628671        36    8.088733 -123.469807
65 + feature_81 -1   0.3192310        35    7.769502 -125.496411
66 + feature_30 -1   0.3102960        34    7.459206 -127.572121
67 + feature_17 -1   0.2442365        33    7.214970 -128.901222
68 + feature_75 -1   0.3164986        32    6.898471 -131.387041
69 + feature_53 -1   0.4561204        31    6.442351 -136.227672
70 + feature_21 -1   0.5123011        30    5.930049 -142.513763
71 + feature_39 -1   0.2704700        29    5.659579 -145.182060
72 + feature_71 -1   0.1846113        28    5.474968 -146.498373
73 + feature_12 -1   0.1455690        27    5.329399 -147.193170
74 + feature_59 -1   0.1167323        26    5.212667 -147.407861
75 + feature_60 -1   0.1062870        25    5.106380 -147.467949
76 + feature_98 -1   0.1145023        24    4.991877 -147.735810
~~~
{: .output}



~~~
plot(coef(forward), beta[names(coef(forward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-5-1.png" title="plot of chunk unnamed-chunk-5" alt="plot of chunk unnamed-chunk-5" width="612" style="display: block; margin: auto;" />


~~~
## note about backward/both, not a challenge
all <- lm(y ~ . + 0, data = xy)
backward <- step(
    all,
    scope = formula(all),
    direction = "backward",
    trace = 0
)
backward$anova
~~~
{: .language-r}



~~~
          Step Df     Deviance Resid. Df Resid. Dev       AIC
1              NA           NA         1  0.1998539 -423.5339
2 - feature_68  1 5.263523e-05         2  0.1999065 -425.5076
3 - feature_47  1 6.744652e-04         3  0.2005810 -427.1707
4 - feature_34  1 1.396204e-03         4  0.2019772 -428.4771
5  - feature_4  1 1.535461e-03         5  0.2035126 -429.7197
6 - feature_18  1 3.333944e-03         6  0.2068466 -430.0948
~~~
{: .output}



~~~
plot(coef(backward), beta[names(coef(backward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-6-1.png" title="plot of chunk unnamed-chunk-6" alt="plot of chunk unnamed-chunk-6" width="612" style="display: block; margin: auto;" />


{% include links.md %}
