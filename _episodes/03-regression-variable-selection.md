---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 03-regression-variable-selection.md in _episodes_rmd/
title: "Stepwise feature selection for regression"
teaching: 0
exercises: 0
questions:
- "Why would we want to find a subset of features
  that are associated with an outcome?"
- "How can we iteratively find a good subset of our features
  variables to use for regression?"
- "What are some risks and downsides of iterative feature
  selection?"
objectives:
- "Understand multiple regression in a biomedical context."
- "Understand how to fit a stepwise regression model."
keypoints:
- "Sets of features can be more predictive and provide
  a better explanation than a single feature alone."
- "Stepwise regression allows us to find a set of features that
  are associated with an outcome (eg, age)."
- "Stepwise regression will tend to retain only one
  feature out of many that are correlated."
- "Stepwise regression is not very efficient."
math: yes
---





In the previous 

Another way of modelling these data is to model age as 

$$
    y_j = \beta_0 + \beta_1 X_1 + \dots \beta_p X_p + \epsilon_j
$$



~~~
suppressPackageStartupMessages({
    library("glmnet")
    library("limma")
    library("minfi")
    library("here")
    library("broom")
})

if (!file.exists(here("data/methylation.rds"))) {
    source(here("data/methylation.R"))
}
norm <- readRDS(here("data/methylation.rds"))

lim <- norm
y <- lim$Age
X <- getM(lim)
~~~
{: .language-r}

However when the number of predictors is greater than the number of samples
(basically always true in genetics) it isn't possible to include everything!

There are some techniques that you can use to find a set of predictors!

- screening (correlation etc): bad, don't do
- screening (variance): not necessarily bad if the screening variable is sensible
- forward/reverse/best subset selection


~~~
if (!file.exists(here("data/synthetic.rds"))) {
    source(here("data/synthetic.R"))
}
synthetic <- readRDS(here("data/synthetic.rds"))
~~~
{: .language-r}





~~~
X <- assay(synthetic)
y <- synthetic$age
beta <- rowData(synthetic)$true_beta
names(beta) <- rownames(synthetic)
## challenge 3: fit y on x univariate
## compare with true betas
cc <- sapply(seq_len(nrow(X)), function(i) {
    coef(lm(y ~ X[i, ]))[[2]]
})
plot(cc, beta, pch = 19, cex = 0.5)
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-4-1.png" title="plot of chunk unnamed-chunk-4" alt="plot of chunk unnamed-chunk-4" width="612" style="display: block; margin: auto;" />




> ## Exercise
> Perform forward subset selection on the methylation data.
> 
> 
> > ## Solution
> > 
> > 
> {: .solution}
{: .challenge}




~~~
## challenge 4: forward selection
## compare with true betas
xy <- as.data.frame(cbind(t(X), y = y))
int <- lm(y ~ 1, data = xy)
all <- lm(y ~ . + 0, data = xy)
forward <- step(
    int,
    scope = list(upper = formula(all), lower = formula(int)),
    direction = "forward",
    trace = 0
)
forward$anova
~~~
{: .language-r}



~~~
           Step Df     Deviance Resid. Df Resid. Dev         AIC
1               NA           NA        99 4782.75000 388.7600788
2  + feature_83 -1 1010.6444267        98 3772.10557 367.0218446
3  + feature_38 -1  761.3592471        97 3010.74633 346.4773090
4  + feature_54 -1  457.5274893        96 2553.21884 331.9939945
5   + feature_5 -1  459.1275235        95 2094.09131 314.1704812
6  + feature_72 -1  352.2803854        94 1741.81093 297.7510428
7  + feature_70 -1  429.2708142        93 1312.54011 271.4549371
8  + feature_27 -1  278.6893440        92 1033.85077 249.5875535
9  + feature_96 -1  203.4850040        91  830.36577 229.6696099
10 + feature_44 -1  132.8190055        90  697.54676 214.2399365
11 + feature_18 -1  134.9145506        89  562.63221 194.7455960
12 + feature_24 -1  123.3892432        88  439.24297 171.9882528
13  + feature_4 -1   99.6160389        87  339.62693 148.2677557
14 + feature_17 -1   81.4055643        86  258.22136 122.8647027
15 + feature_15 -1   31.1305327        85  227.09083 112.0179885
16 + feature_89 -1   29.4194578        84  197.67137 100.1435731
17 + feature_61 -1   21.9339574        83  175.73742  90.3820735
18 + feature_29 -1   29.2998802        82  146.43753  74.1428768
19 + feature_23 -1   16.0781249        81  130.35941  64.5125142
20 + feature_31 -1   17.8897777        80  112.46963  51.7513064
21 + feature_92 -1   11.6011100        79  100.86852  42.8647723
22 + feature_82 -1    7.1484215        78   93.72010  37.5142503
23 + feature_85 -1    5.7944816        77   87.92562  33.1321034
24 + feature_73 -1    5.6576220        76   82.26800  28.4811990
25 + feature_34 -1    4.7970354        75   77.47096  24.4732992
26 + feature_42 -1    4.0784154        74   73.39255  21.0652196
27 + feature_66 -1    3.5972237        73   69.79532  18.0396810
28 + feature_20 -1    2.4776957        72   67.31763  16.4251932
29 + feature_11 -1    3.0880238        71   64.22960  13.7294026
30 + feature_32 -1    2.2749554        70   61.95465  12.1232443
31 + feature_88 -1    2.3282484        69   59.62640  10.2928232
32 + feature_50 -1    1.9542756        68   57.67212   8.9603746
33 + feature_63 -1    2.0289213        67   55.64320   7.3789736
34 + feature_62 -1    2.2780370        66   53.36517   5.1988014
35 + feature_19 -1    2.3851548        65   50.98001   2.6263422
36 + feature_64 -1    2.4264335        64   48.55358  -0.2502314
37 + feature_36 -1    2.0881742        63   46.46540  -2.6462173
38 + feature_94 -1    1.6460871        62   44.81932  -4.2530983
39  + feature_8 -1    1.6818383        61   43.13748  -6.0778018
40 + feature_46 -1    1.7857521        60   41.35173  -8.3056037
41 + feature_80 -1    1.2836274        59   40.06810  -9.4589727
42 + feature_41 -1    1.9601762        58   38.10792 -12.4748002
43 + feature_69 -1    1.2505977        57   36.85732 -13.8115830
44 + feature_79 -1    0.9215992        56   35.93573 -14.3438260
45 + feature_16 -1    1.2060108        55   34.72971 -15.7574547
46 + feature_90 -1    1.7158653        54   33.01385 -18.8243048
47 + feature_74 -1    1.0966114        53   31.91724 -20.2023961
48 + feature_71 -1    1.3218192        52   30.59542 -22.4319915
49 + feature_56 -1    0.8718286        51   29.72359 -23.3229188
50 + feature_13 -1    1.2973133        50   28.42628 -25.7856242
51 + feature_95 -1    0.6272877        49   27.79899 -26.0170541
~~~
{: .output}



~~~
plot(coef(forward), beta[names(coef(forward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-5-1.png" title="plot of chunk unnamed-chunk-5" alt="plot of chunk unnamed-chunk-5" width="612" style="display: block; margin: auto;" />


~~~
## note about backward/both, not a challenge
all <- lm(y ~ . + 0, data = xy)
backward <- step(
    all,
    scope = formula(all),
    direction = "backward",
    trace = 0
)
backward$anova
~~~
{: .language-r}



~~~
          Step Df    Deviance Resid. Df Resid. Dev       AIC
1              NA          NA         1   2.474032 -171.9321
2 - feature_52  1 0.003187275         2   2.477219 -173.8034
3 - feature_28  1 0.005971820         3   2.483191 -175.5626
4 - feature_30  1 0.016204769         4   2.499396 -176.9121
5 - feature_69  1 0.010955483         5   2.510351 -178.4747
~~~
{: .output}



~~~
plot(coef(backward), beta[names(coef(backward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-6-1.png" title="plot of chunk unnamed-chunk-6" alt="plot of chunk unnamed-chunk-6" width="612" style="display: block; margin: auto;" />


{% include links.md %}
