---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 02-high-dimensional-regression_b.md in _episodes_rmd/
title: "Stepwise feature selection for regression"
teaching: 0
exercises: 0
questions:
- "Why would we want to find a subset of features
  that are associated with an outcome?"
- "How can we iteratively find a good subset of our features
  variables to use for regression?"
- "What are some risks and downsides of iterative feature
  selection?"
objectives:
- "Understand multiple regression in a biomedical context."
- "Understand how to fit a stepwise regression model."
keypoints:
- "Sets of features can be more predictive and provide
  a better explanation than a single feature alone."
- "Stepwise regression allows us to find a set of features that
  are associated with an outcome (eg, age)."
- "Stepwise regression will tend to retain only one
  feature out of many that are correlated."
- "Stepwise regression is not very efficient."
math: yes
---





In the previous 

Another way of modelling these data is to model age as 

$$
    y_j = \beta_0 + \beta_1 X_1 + \dots \beta_p X_p + \epsilon_j
$$



~~~
suppressPackageStartupMessages({
    library("glmnet")
    library("limma")
    library("minfi")
    library("here")
    library("broom")
})

if (!file.exists(here("data/methylation.rds"))) {
    source(here("data/methylation.R"))
}
norm <- readRDS(here("data/methylation.rds"))

lim <- norm
y <- lim$Age
X <- getM(lim)
~~~
{: .language-r}

However when the number of predictors is greater than the number of samples
(basically always true in genetics) it isn't possible to include everything!

There are some techniques that you can use to find a set of predictors!

- screening (correlation etc): bad, don't do
- screening (variance): not necessarily bad if the screening variable is sensible
- forward/reverse/best subset selection


~~~
if (!file.exists(here("data/synthetic.rds"))) {
    source(here("data/synthetic.R"))
}
synthetic <- readRDS(here("data/synthetic.rds"))
~~~
{: .language-r}





~~~
X <- assay(synthetic)
y <- synthetic$age
beta <- rowData(synthetic)$true_beta
names(beta) <- rownames(synthetic)
## challenge 3: fit y on x univariate
## compare with true betas
cc <- sapply(seq_len(nrow(X)), function(i) {
    coef(lm(y ~ X[i, ]))[[2]]
})
plot(cc, beta, pch = 19, cex = 0.5)
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-4-1.png" title="plot of chunk unnamed-chunk-4" alt="plot of chunk unnamed-chunk-4" width="612" style="display: block; margin: auto;" />




> ## Exercise
> Perform forward subset selection on the methylation data.
> 
> 
> > ## Solution
> > 
> > 
> {: .solution}
{: .challenge}




~~~
## challenge 4: forward selection
## compare with true betas
xy <- as.data.frame(cbind(t(X), y = y))
int <- lm(y ~ 1, data = xy)
all <- lm(y ~ . + 0, data = xy)
forward <- step(
    int,
    scope = list(upper = formula(all), lower = formula(int)),
    direction = "forward",
    trace = 0
)
forward$anova
~~~
{: .language-r}



~~~
           Step Df     Deviance Resid. Df  Resid. Dev         AIC
1               NA           NA        99 4972.440000  392.649576
2  + feature_48 -1 1365.5320368        98 3606.907963  362.543598
3   + feature_4 -1  551.9026653        97 3055.005298  347.936642
4  + feature_42 -1  568.1425845        96 2486.862713  329.360705
5  + feature_54 -1  388.5751018        95 2098.287612  314.370668
6  + feature_46 -1  367.1420687        94 1731.145543  297.136845
7  + feature_57 -1  260.9131309        93 1470.232412  282.800558
8  + feature_93 -1  245.9181158        92 1224.314296  266.496602
9  + feature_24 -1  188.7568839        91 1035.557412  251.752494
10 + feature_15 -1  191.2302405        90  844.327172  233.336988
11 + feature_18 -1  129.0622257        89  715.264946  218.748284
12 + feature_38 -1  126.6115367        88  588.653409  201.266739
13  + feature_1 -1  123.3629993        87  465.290410  179.749156
14 + feature_16 -1   77.9154387        86  387.374971  163.422296
15 + feature_64 -1   52.1834878        85  335.191484  150.953178
16 + feature_33 -1   60.4295693        84  274.761914  133.073477
17 + feature_49 -1   47.4208541        83  227.341060  116.128117
18 + feature_13 -1   46.1914409        82  181.149619   95.415313
19 + feature_23 -1   17.8668460        81  163.282773   87.031332
20 + feature_86 -1   16.6363088        80  146.646465   78.285450
21 + feature_29 -1   21.4338152        79  125.212649   64.484330
22 + feature_10 -1   10.6385634        78  114.574086   57.605147
23 + feature_75 -1   10.0978771        77  104.476209   50.378919
24 + feature_92 -1    9.0320308        76   95.444178   43.337137
25 + feature_60 -1    6.5277141        75   88.916464   38.252714
26  + feature_5 -1    6.3107554        74   82.605709   32.890860
27 + feature_98 -1    5.1403817        73   77.465327   28.466026
28 + feature_12 -1    4.7082433        72   72.757084   24.195608
29 + feature_74 -1    7.5019607        71   65.255123   15.313437
30 + feature_66 -1    4.2224040        70   61.032719   10.623991
31  + feature_7 -1    3.0716758        69   57.961043    7.460093
32 + feature_59 -1    3.6484347        68   54.312608    2.958621
33 + feature_79 -1    3.9901662        67   50.322442   -2.671904
34 + feature_89 -1    4.1861183        66   46.136324   -9.356961
35 + feature_90 -1    3.1140533        65   43.022271  -14.345228
36 + feature_35 -1    2.3359704        64   40.686300  -17.927875
37 + feature_11 -1    2.2963929        63   38.389907  -21.737559
38 + feature_27 -1    2.0141204        62   36.375787  -25.126683
39 + feature_19 -1    1.8132018        61   34.562585  -28.239844
40 + feature_68 -1    1.5632217        60   32.999363  -30.868192
41 + feature_53 -1    1.2112632        59   31.788100  -32.607817
42 + feature_30 -1    1.3657971        58   30.422303  -34.999419
43 + feature_81 -1    1.9055289        57   28.516774  -39.467770
44 + feature_22 -1    1.4116508        56   27.105123  -42.544742
45 + feature_88 -1    1.4263222        55   25.678801  -45.950439
46 + feature_37 -1    1.8513483        54   23.827453  -51.433179
47 + feature_28 -1    1.2752964        53   22.552156  -54.933949
48 + feature_71 -1    1.8652793        52   20.686877  -61.567064
49 + feature_82 -1    1.0903336        51   19.596544  -64.981699
50 + feature_84 -1    0.9777140        50   18.618829  -68.099678
51 + feature_77 -1    1.1222783        49   17.496551  -72.316640
52 + feature_21 -1    0.9495945        48   16.546957  -75.896799
53 + feature_62 -1    0.9633184        47   15.583638  -79.894865
54 + feature_52 -1    1.1602436        46   14.423395  -85.631867
55 + feature_39 -1    0.6688235        45   13.754571  -88.379897
56 + feature_55 -1    0.6806317        44   13.073939  -91.454929
57 + feature_25 -1    0.5250572        43   12.548882  -93.553859
58 + feature_45 -1    0.3836453        42   12.165237  -94.658773
59 + feature_94 -1    0.3599419        41   11.805295  -95.662202
60 + feature_70 -1    0.3002345        40   11.505061  -96.238320
61  + feature_8 -1    0.3036099        39   11.201451  -96.912689
62 + feature_51 -1    0.3060520        38   10.895399  -97.682963
63 + feature_20 -1    0.2726278        37   10.622771  -98.217030
64 + feature_56 -1    0.4066521        36   10.216119 -100.120345
65  + feature_6 -1    0.4394469        35    9.776672 -102.517107
66 + feature_96 -1    0.3898081        34    9.386864 -104.585896
67 + feature_17 -1    0.1980493        33    9.188814 -104.718327
68 + feature_58 -1    0.2316064        32    8.957208 -105.271162
69 + feature_14 -1    0.2420515        31    8.715156 -106.010656
70 + feature_40 -1    0.2605294        30    8.454627 -107.045631
71 + feature_44 -1    0.1692402        29    8.285387 -107.067684
72 + feature_67 -1    0.1663882        28    8.118999 -107.096336
73 + feature_73 -1    0.2562754        27    7.862723 -108.303717
74 + feature_97 -1    0.2131336        26    7.649590 -109.051819
~~~
{: .output}



~~~
plot(coef(forward), beta[names(coef(forward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-5-1.png" title="plot of chunk unnamed-chunk-5" alt="plot of chunk unnamed-chunk-5" width="612" style="display: block; margin: auto;" />


~~~
## note about backward/both, not a challenge
all <- lm(y ~ . + 0, data = xy)
backward <- step(
    all,
    scope = formula(all),
    direction = "backward",
    trace = 0
)
backward$anova
~~~
{: .language-r}



~~~
          Step Df     Deviance Resid. Df Resid. Dev       AIC
1              NA           NA         1  0.2717849 -392.7915
2  - feature_4  1 1.174252e-06         2  0.2717860 -394.7910
3 - feature_55  1 3.686465e-05         3  0.2718229 -396.7775
4 - feature_61  1 8.010289e-04         4  0.2726239 -398.4832
5 - feature_74  1 4.791786e-04         5  0.2731031 -400.3076
~~~
{: .output}



~~~
plot(coef(backward), beta[names(coef(backward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-6-1.png" title="plot of chunk unnamed-chunk-6" alt="plot of chunk unnamed-chunk-6" width="612" style="display: block; margin: auto;" />


{% include links.md %}
