---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 02-high-dimensional-regression_b.md in _episodes_rmd/
title: "Stepwise feature selection for regression"
teaching: 0
exercises: 0
questions:
- "Why would we want to find a subset of features
  that are associated with an outcome?"
- "How can we iteratively find a good subset of our features
  variables to use for regression?"
- "What are some risks and downsides of iterative feature
  selection?"
objectives:
- "Understand multiple regression in a biomedical context."
- "Understand how to fit a stepwise regression model."
keypoints:
- "Sets of features can be more predictive and provide
  a better explanation than a single feature alone."
- "Stepwise regression allows us to find a set of features that
  are associated with an outcome (eg, age)."
- "Stepwise regression will tend to retain only one
  feature out of many that are correlated."
- "Stepwise regression is not very efficient."
math: yes
---





In the previous 

Another way of modelling these data is to model age as 

$$
    y_j = \beta_0 + \beta_1 X_1 + \dots \beta_p X_p + \epsilon_j
$$



~~~
suppressPackageStartupMessages({
    library("glmnet")
    library("limma")
    library("minfi")
    library("here")
    library("broom")
})

if (!file.exists(here("data/methylation.rds"))) {
    source(here("data/methylation.R"))
}
norm <- readRDS(here("data/methylation.rds"))

lim <- norm
y <- lim$Age
X <- getM(lim)
~~~
{: .language-r}

However when the number of predictors is greater than the number of samples
(basically always true in genetics) it isn't possible to include everything!

There are some techniques that you can use to find a set of predictors!

- screening (correlation etc): bad, don't do
- screening (variance): not necessarily bad if the screening variable is sensible
- forward/reverse/best subset selection


~~~
if (!file.exists(here("data/synthetic.rds"))) {
    source(here("data/synthetic.R"))
}
synthetic <- readRDS(here("data/synthetic.rds"))
~~~
{: .language-r}





~~~
X <- assay(synthetic)
y <- synthetic$age
beta <- rowData(synthetic)$true_beta
names(beta) <- rownames(synthetic)
## challenge 3: fit y on x univariate
## compare with true betas
cc <- sapply(seq_len(nrow(X)), function(i) {
    coef(lm(y ~ X[i, ]))[[2]]
})
plot(cc, beta, pch = 19, cex = 0.5)
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-4-1.png" title="plot of chunk unnamed-chunk-4" alt="plot of chunk unnamed-chunk-4" width="612" style="display: block; margin: auto;" />




> ## Exercise
> Perform forward subset selection on the methylation data.
> 
> 
> > ## Solution
> > 
> > 
> {: .solution}
{: .challenge}




~~~
## challenge 4: forward selection
## compare with true betas
xy <- as.data.frame(cbind(t(X), y = y))
int <- lm(y ~ 1, data = xy)
all <- lm(y ~ . + 0, data = xy)
forward <- step(
    int,
    scope = list(upper = formula(all), lower = formula(int)),
    direction = "forward",
    trace = 0
)
forward$anova
~~~
{: .language-r}



~~~
           Step Df    Deviance Resid. Df  Resid. Dev          AIC
1               NA          NA        99 3786.640000  365.4064175
2  + feature_80 -1 851.9876216        98 2934.652378  341.9174099
3  + feature_94 -1 425.2654656        97 2509.386913  328.2623558
4  + feature_67 -1 393.5485868        96 2115.838326  313.2036199
5  + feature_23 -1 348.6042423        95 1767.234084  297.2000753
6  + feature_30 -1 346.2406508        94 1420.993433  277.3941321
7  + feature_90 -1 368.8890416        93 1052.104391  249.3377434
8   + feature_6 -1 323.5132452        92  728.591146  214.5942547
9  + feature_11 -1 215.6251373        91  512.966009  181.5039397
10 + feature_69 -1 183.0179429        90  329.948066  139.3765080
11  + feature_8 -1  90.5911564        89  239.356910  109.2785597
12 + feature_72 -1  35.3658583        88  203.991051   95.2905940
13 + feature_37 -1  35.6835418        87  168.307509   78.0622533
14 + feature_68 -1  54.8907671        86  113.416742   40.5898834
15 + feature_27 -1  14.4563723        85   98.960370   28.9549281
16 + feature_31 -1   7.0183639        84   91.942006   23.5987823
17 + feature_61 -1   8.7972533        83   83.144753   15.5412911
18 + feature_44 -1   7.0967287        82   76.048024    8.6194850
19 + feature_47 -1   4.0912659        81   71.956758    5.0895171
20 + feature_26 -1   5.0787877        80   66.877970   -0.2300564
21 + feature_42 -1   4.6795775        79   62.198393   -5.4841023
22 + feature_60 -1   3.8494751        78   58.348918   -9.8729374
23  + feature_3 -1   2.9340451        77   55.414873  -13.0322168
24 + feature_46 -1   2.8640573        76   52.550815  -16.3389572
25 + feature_64 -1   2.3634805        75   50.187335  -18.9407483
26 + feature_24 -1   1.9059740        74   48.281361  -20.8124603
27 + feature_45 -1   1.7424390        73   46.538922  -22.4881195
28 + feature_78 -1   1.4512582        72   45.087664  -23.6561511
29 + feature_70 -1   1.3722753        71   43.715388  -24.7470011
30 + feature_85 -1   1.6878845        70   42.027504  -26.6845930
31 + feature_53 -1   1.5154682        69   40.512036  -28.3571080
32 + feature_63 -1   1.2557287        68   39.256307  -29.5058068
33 + feature_88 -1   1.1220516        67   38.134255  -30.4057218
34  + feature_2 -1   1.0473616        66   37.086894  -31.1906548
35 + feature_21 -1   1.1698323        65   35.917061  -32.3957756
36 + feature_35 -1   1.0432807        64   34.873781  -33.3434909
37 + feature_97 -1   1.3708589        63   33.502922  -35.3537535
38 + feature_38 -1   0.9100973        62   32.592824  -36.1078032
39 + feature_14 -1   0.9957099        61   31.597115  -37.2104382
40 + feature_59 -1   1.2146504        60   30.382464  -39.1304583
41 + feature_95 -1   1.2149665        59   29.167498  -41.2115194
42 + feature_22 -1   1.0911064        58   28.076391  -43.0241135
43 + feature_98 -1   0.9903231        57   27.086068  -44.6150683
44 + feature_16 -1   0.6802908        56   26.405777  -45.1587362
45 + feature_29 -1   1.0645557        55   25.341222  -47.2737802
46 + feature_58 -1   1.1933524        54   24.147869  -50.0974038
47 + feature_65 -1   0.7045217        53   23.443348  -51.0583415
48 + feature_32 -1   1.0039046        52   22.439443  -53.4349929
49 + feature_40 -1   0.7064435        51   21.732999  -54.6338366
50 + feature_96 -1   0.7945148        50   20.938485  -56.3581346
51 + feature_71 -1   0.6827173        49   20.255767  -57.6730619
52 + feature_84 -1   0.6222970        48   19.633470  -58.7934398
53 + feature_15 -1   0.5552352        47   19.078235  -59.6622012
54 + feature_87 -1   0.7332172        46   18.345018  -61.5812141
55 + feature_91 -1   0.6726606        45   17.672357  -63.3168491
56 + feature_81 -1   0.6143561        44   17.058001  -64.8550800
57 + feature_66 -1   0.6227374        43   16.435264  -66.5740914
58 + feature_50 -1   1.0056522        42   15.429612  -70.8881676
59 + feature_51 -1   0.7643128        41   14.665299  -73.9686091
60  + feature_4 -1   0.6933573        40   13.971942  -76.8119030
61 + feature_76 -1   0.7697243        39   13.202217  -80.4785385
62 + feature_92 -1   0.7068027        38   12.495415  -83.9808428
63 + feature_34 -1   0.8210284        37   11.674386  -88.7772943
64 + feature_89 -1   1.0401556        36   10.634231  -96.1092073
65 + feature_93 -1   0.5341625        35   10.100068  -99.2628009
66  + feature_1 -1   0.3462249        34    9.753843 -100.7508789
67  + feature_7 -1   0.3953371        33    9.358506 -102.8884495
68  + feature_9 -1   0.3237566        32    9.034750 -104.4091973
69 + feature_75 -1   0.3060343        31    8.728715 -105.8551979
70 + feature_25 -1   0.2405656        30    8.488150 -106.6499137
71 + feature_41 -1   0.2306300        29    8.257520 -107.4045915
72 + feature_33 -1   0.2690275        28    7.988492 -108.7168153
73 + feature_83 -1   0.2966107        27    7.691882 -110.5004763
74 + feature_55 -1   0.3612827        26    7.330599 -113.3112979
75 + feature_43 -1   0.3076031        25    7.022996 -115.5980312
76 + feature_49 -1   0.1954490        24    6.827547 -116.4204760
77 + feature_19 -1   0.2098120        23    6.617735 -117.5417060
78 + feature_20 -1   0.3440037        22    6.273731 -120.8798949
79 + feature_77 -1   0.1654876        21    6.108243 -121.5530954
80 + feature_48 -1   0.2265841        20    5.881659 -123.3331281
81 + feature_36 -1   0.1467588        19    5.734900 -123.8599802
82 + feature_28 -1   0.1164896        18    5.618411 -123.9121334
~~~
{: .output}



~~~
plot(coef(forward), beta[names(coef(forward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-5-1.png" title="plot of chunk unnamed-chunk-5" alt="plot of chunk unnamed-chunk-5" width="612" style="display: block; margin: auto;" />


~~~
## note about backward/both, not a challenge
all <- lm(y ~ . + 0, data = xy)
backward <- step(
    all,
    scope = formula(all),
    direction = "backward",
    trace = 0
)
backward$anova
~~~
{: .language-r}



~~~
          Step Df     Deviance Resid. Df Resid. Dev       AIC
1              NA           NA         1 0.07902105 -516.3211
2 - feature_22  1 0.0001713200         2 0.07919237 -518.1046
3 - feature_56  1 0.0007787116         3 0.07997108 -519.1260
4 - feature_36  1 0.0013072198         4 0.08127830 -519.5046
5 - feature_32  1 0.0015305252         5 0.08280882 -519.6391
~~~
{: .output}



~~~
plot(coef(backward), beta[names(coef(backward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-6-1.png" title="plot of chunk unnamed-chunk-6" alt="plot of chunk unnamed-chunk-6" width="612" style="display: block; margin: auto;" />


{% include links.md %}
