---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 02-high-dimensional-regression_b.md in _episodes_rmd/
title: "Stepwise feature selection for regression"
teaching: 0
exercises: 0
questions:
- "Why would we want to find a subset of features
  that are associated with an outcome?"
- "How can we iteratively find a good subset of our features
  variables to use for regression?"
- "What are some risks and downsides of iterative feature
  selection?"
objectives:
- "Understand multiple regression in a biomedical context."
- "Understand how to fit a stepwise regression model."
keypoints:
- "Sets of features can be more predictive and provide
  a better explanation than a single feature alone."
- "Stepwise regression allows us to find a set of features that
  are associated with an outcome (eg, age)."
- "Stepwise regression will tend to retain only one
  feature out of many that are correlated."
- "Stepwise regression is not very efficient."
math: yes
---





In the previous 

Another way of modelling these data is to model age as 

$$
    y_j = \beta_0 + \beta_1 X_1 + \dots \beta_p X_p + \epsilon_j
$$



~~~
suppressPackageStartupMessages({
    library("glmnet")
    library("limma")
    library("minfi")
    library("here")
    library("broom")
})

if (!file.exists(here("data/methylation.rds"))) {
    source(here("data/methylation.R"))
}
norm <- readRDS(here("data/methylation.rds"))

lim <- norm
y <- lim$Age
X <- getM(lim)
~~~
{: .language-r}

However when the number of predictors is greater than the number of samples
(basically always true in genetics) it isn't possible to include everything!

There are some techniques that you can use to find a set of predictors!

- screening (correlation etc): bad, don't do
- screening (variance): not necessarily bad if the screening variable is sensible
- forward/reverse/best subset selection


~~~
if (!file.exists(here("data/synthetic.rds"))) {
    source(here("data/synthetic.R"))
}
synthetic <- readRDS(here("data/synthetic.rds"))
~~~
{: .language-r}





~~~
X <- assay(synthetic)
y <- synthetic$age
beta <- rowData(synthetic)$true_beta
names(beta) <- rownames(synthetic)
## challenge 3: fit y on x univariate
## compare with true betas
cc <- sapply(seq_len(nrow(X)), function(i) {
    coef(lm(y ~ X[i, ]))[[2]]
})
plot(cc, beta, pch = 19, cex = 0.5)
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-4-1.png" title="plot of chunk unnamed-chunk-4" alt="plot of chunk unnamed-chunk-4" width="612" style="display: block; margin: auto;" />




> ## Exercise
> Perform forward subset selection on the methylation data.
> 
> 
> > ## Solution
> > 
> > 
> {: .solution}
{: .challenge}




~~~
## challenge 4: forward selection
## compare with true betas
xy <- as.data.frame(cbind(t(X), y = y))
int <- lm(y ~ 1, data = xy)
all <- lm(y ~ . + 0, data = xy)
forward <- step(
    int,
    scope = list(upper = formula(all), lower = formula(int)),
    direction = "forward",
    trace = 0
)
forward$anova
~~~
{: .language-r}



~~~
           Step Df     Deviance Resid. Df  Resid. Dev         AIC
1               NA           NA        99 5732.990000  406.882230
2  + feature_29 -1 1.180467e+03        98 4552.522507  385.826657
3  + feature_68 -1 1.132983e+03        97 3419.539213  359.209090
4  + feature_50 -1 6.078505e+02        96 2811.688700  341.637036
5  + feature_24 -1 6.688141e+02        95 2142.874641  316.473331
6  + feature_62 -1 5.170739e+02        94 1625.800720  290.858554
7  + feature_14 -1 3.211496e+02        93 1304.651110  270.852075
8  + feature_97 -1 2.673912e+02        92 1037.259948  249.916766
9  + feature_65 -1 2.444214e+02        91  792.838595  225.044948
10 + feature_83 -1 2.486951e+02        90  544.143477  189.404277
11 + feature_43 -1 1.138759e+02        89  430.267583  167.923711
12 + feature_48 -1 1.310982e+02        88  299.169417  133.583984
13 + feature_51 -1 1.241182e+02        87  175.051248   81.990859
14 + feature_13 -1 3.203795e+01        86  143.013293   63.776740
15 + feature_60 -1 2.349365e+01        85  119.519645   47.831056
16 + feature_26 -1 2.226007e+01        84   97.259570   29.221320
17 + feature_52 -1 1.869296e+01        83   78.566612    9.877663
18 + feature_10 -1 9.742898e+00        82   68.823714   -1.362182
19  + feature_7 -1 7.098539e+00        81   61.725175  -10.247831
20 + feature_70 -1 3.905754e+00        80   57.819421  -14.784546
21 + feature_88 -1 2.918822e+00        79   54.900599  -17.964593
22 + feature_15 -1 2.800614e+00        78   52.099985  -21.200553
23 + feature_98 -1 2.153450e+00        77   49.946535  -23.421705
24 + feature_19 -1 2.489697e+00        76   47.456838  -26.534956
25  + feature_6 -1 2.414001e+00        75   45.042838  -29.755620
26 + feature_73 -1 1.828004e+00        74   43.214834  -31.898637
27 + feature_84 -1 1.915534e+00        73   41.299300  -34.432464
28 + feature_71 -1 2.151939e+00        72   39.147361  -37.783719
29 + feature_82 -1 1.687963e+00        71   37.459398  -40.191257
30 + feature_12 -1 1.137924e+00        70   36.321474  -41.276105
31 + feature_75 -1 1.286943e+00        69   35.034531  -42.883602
32 + feature_44 -1 1.241619e+00        68   33.792911  -44.491913
33 + feature_35 -1 1.134046e+00        67   32.658866  -45.905383
34 + feature_11 -1 1.305084e+00        66   31.353782  -47.983529
35 + feature_76 -1 1.028653e+00        65   30.325129  -49.319348
36 + feature_94 -1 1.192351e+00        64   29.132778  -51.330627
37 + feature_72 -1 1.032694e+00        63   28.100084  -52.939764
38 + feature_85 -1 1.063096e+00        62   27.036988  -54.796434
39 + feature_30 -1 5.925175e-01        61   26.444470  -55.012311
40 + feature_39 -1 8.225595e-01        60   25.621911  -56.172231
41 + feature_45 -1 7.596192e-01        59   24.862292  -57.181792
42 + feature_25 -1 8.197588e-01        58   24.042533  -58.534572
43 + feature_67 -1 1.190799e+00        57   22.851734  -61.614317
44 + feature_18 -1 1.065318e+00        56   21.786416  -64.388353
45 + feature_77 -1 8.240353e-01        55   20.962381  -66.244075
46  + feature_3 -1 7.092388e-01        54   20.253142  -67.686025
47 + feature_64 -1 7.244275e-01        53   19.528714  -69.328427
48 + feature_36 -1 4.827173e-01        52   19.045997  -69.831323
49 + feature_22 -1 4.412487e-01        51   18.604748  -70.175334
50 + feature_16 -1 7.286916e-01        50   17.876057  -72.170798
51 + feature_57 -1 5.478712e-01        49   17.328186  -73.283578
52 + feature_32 -1 6.899398e-01        48   16.638246  -75.346617
53  + feature_4 -1 8.106488e-01        47   15.827597  -78.341512
54 + feature_21 -1 7.333029e-01        46   15.094294  -81.085339
55 + feature_37 -1 5.700153e-01        45   14.524279  -82.934853
56 + feature_90 -1 6.350760e-01        44   13.889203  -85.405842
57 + feature_33 -1 6.128399e-01        43   13.276363  -87.918495
58  + feature_1 -1 5.903009e-01        42   12.686062  -90.466627
59 + feature_42 -1 6.855301e-01        41   12.000532  -94.021920
60 + feature_53 -1 8.799638e-01        40   11.120568  -99.637380
61 + feature_80 -1 5.093970e-01        39   10.611171 -102.326286
62 + feature_79 -1 4.949114e-01        38   10.116260 -105.102619
63 + feature_59 -1 5.790712e-01        37    9.537189 -108.997145
64 + feature_23 -1 5.090913e-01        36    9.028097 -112.482856
65 + feature_40 -1 9.915540e-01        35    8.036543 -122.117114
66  + feature_2 -1 6.805247e-01        34    7.356018 -128.965137
67 + feature_95 -1 7.218291e-01        33    6.634189 -137.293370
68 + feature_17 -1 3.189631e-01        32    6.315226 -140.220659
69 + feature_69 -1 2.192296e-01        31    6.095997 -141.753790
70  + feature_9 -1 2.210506e-01        30    5.874946 -143.447329
71 + feature_34 -1 2.253789e-01        29    5.649567 -145.359123
72 + feature_86 -1 3.199310e-01        28    5.329636 -149.188719
73 + feature_58 -1 2.037151e-01        27    5.125921 -151.085995
74 + feature_61 -1 1.920572e-01        26    4.933864 -152.904775
75 + feature_78 -1 2.289252e-01        25    4.704939 -155.655744
76 + feature_91 -1 1.883524e-01        24    4.516586 -157.741372
77 + feature_46 -1 2.414941e-01        23    4.275092 -161.236451
78  + feature_8 -1 2.901515e-01        22    3.984941 -166.264774
79 + feature_56 -1 2.128570e-01        21    3.772084 -169.754262
80 + feature_49 -1 8.758867e-02        20    3.684495 -170.103669
81 + feature_27 -1 1.067240e-01        19    3.577771 -171.043019
82 + feature_63 -1 2.800415e-01        18    3.297730 -177.193596
~~~
{: .output}



~~~
plot(coef(forward), beta[names(coef(forward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-5-1.png" title="plot of chunk unnamed-chunk-5" alt="plot of chunk unnamed-chunk-5" width="612" style="display: block; margin: auto;" />


~~~
## note about backward/both, not a challenge
all <- lm(y ~ . + 0, data = xy)
backward <- step(
    all,
    scope = formula(all),
    direction = "backward",
    trace = 0
)
backward$anova
~~~
{: .language-r}



~~~
         Step Df     Deviance Resid. Df Resid. Dev       AIC
1             NA           NA         1  0.4910658 -333.6347
2 - feature_2  1 0.0004248237         2  0.4914907 -335.5483
~~~
{: .output}



~~~
plot(coef(backward), beta[names(coef(backward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-6-1.png" title="plot of chunk unnamed-chunk-6" alt="plot of chunk unnamed-chunk-6" width="612" style="display: block; margin: auto;" />


{% include links.md %}
