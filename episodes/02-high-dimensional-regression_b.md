---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 02-high-dimensional-regression_b.md in _episodes_rmd/
title: "Stepwise feature selection for regression"
teaching: 0
exercises: 0
questions:
- "Why would we want to find a subset of features
  that are associated with an outcome?"
- "How can we iteratively find a good subset of our features
  variables to use for regression?"
- "What are some risks and downsides of iterative feature
  selection?"
objectives:
- "Understand multiple regression in a biomedical context."
- "Understand how to fit a stepwise regression model."
keypoints:
- "Sets of features can be more predictive and provide
  a better explanation than a single feature alone."
- "Stepwise regression allows us to find a set of features that
  are associated with an outcome (eg, age)."
- "Stepwise regression will tend to retain only one
  feature out of many that are correlated."
- "Stepwise regression is not very efficient."
math: yes
---





In the previous 

Another way of modelling these data is to model age as 

$$
    y_j = \beta_0 + \beta_1 X_1 + \dots \beta_p X_p + \epsilon_j
$$



~~~
suppressPackageStartupMessages({
    library("glmnet")
    library("limma")
    library("minfi")
    library("here")
    library("broom")
})

if (!file.exists(here("data/methylation.rds"))) {
    source(here("data/methylation.R"))
}
norm <- readRDS(here("data/methylation.rds"))

lim <- norm
y <- lim$Age
X <- getM(lim)
~~~
{: .language-r}

However when the number of predictors is greater than the number of samples
(basically always true in genetics) it isn't possible to include everything!

There are some techniques that you can use to find a set of predictors!

- screening (correlation etc): bad, don't do
- screening (variance): not necessarily bad if the screening variable is sensible
- forward/reverse/best subset selection


~~~
if (!file.exists(here("data/synthetic.rds"))) {
    source(here("data/synthetic.R"))
}
synthetic <- readRDS(here("data/synthetic.rds"))
~~~
{: .language-r}





~~~
X <- assay(synthetic)
y <- synthetic$age
beta <- rowData(synthetic)$true_beta
names(beta) <- rownames(synthetic)
## challenge 3: fit y on x univariate
## compare with true betas
cc <- sapply(seq_len(nrow(X)), function(i) {
    coef(lm(y ~ X[i, ]))[[2]]
})
plot(cc, beta, pch = 19, cex = 0.5)
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-4-1.png" title="plot of chunk unnamed-chunk-4" alt="plot of chunk unnamed-chunk-4" width="612" style="display: block; margin: auto;" />




> ## Exercise
> Perform forward subset selection on the methylation data.
> 
> 
> > ## Solution
> > 
> > 
> {: .solution}
{: .challenge}




~~~
## challenge 4: forward selection
## compare with true betas
xy <- as.data.frame(cbind(t(X), y = y))
int <- lm(y ~ 1, data = xy)
all <- lm(y ~ . + 0, data = xy)
forward <- step(
    int,
    scope = list(upper = formula(all), lower = formula(int)),
    direction = "forward",
    trace = 0
)
forward$anova
~~~
{: .language-r}



~~~
           Step Df    Deviance Resid. Df Resid. Dev        AIC
1               NA          NA        99 2539.31000 325.447748
2   + feature_8 -1 608.5016441        98 1930.80836 300.052385
3  + feature_52 -1 490.9446939        97 1439.86366 272.713352
4  + feature_12 -1 213.0489298        96 1226.81473 258.700625
5   + feature_6 -1 222.0320369        95 1004.78270 240.735639
6   + feature_7 -1 219.0425337        94  785.74016 218.145597
7  + feature_48 -1 125.0019073        93  660.73825 202.818759
8  + feature_49 -1  86.1035795        92  574.63467 190.856430
9  + feature_77 -1  83.1721536        91  491.46252 177.221550
10 + feature_24 -1  80.1669925        90  411.29553 161.414182
11 + feature_39 -1  69.0682590        89  342.22727 145.030486
12 + feature_96 -1  59.6474742        88  282.57980 127.879079
13  + feature_5 -1  38.0573817        87  244.52241 115.413679
14 + feature_79 -1  43.8014697        86  200.72094  97.674542
15 + feature_66 -1  20.3444875        85  180.37646  88.987591
16 + feature_93 -1  24.1550691        84  156.22139  76.610397
17 + feature_31 -1  36.8515973        83  119.36979  51.705597
18 + feature_51 -1  14.8623841        82  104.50741  40.408775
19 + feature_65 -1   9.1287224        81   95.37868  33.268493
20 + feature_73 -1   5.5300087        80   89.84867  29.295668
21 + feature_68 -1   5.6175676        79   84.23111  24.839411
22  + feature_4 -1   3.7717559        78   80.45935  22.258192
23 + feature_85 -1   3.8634768        77   76.59587  19.337303
24 + feature_61 -1   3.6657927        76   72.93008  16.433101
25 + feature_25 -1   3.1312963        75   69.79879  14.044643
26 + feature_41 -1   2.3380781        74   67.46071  12.637513
27 + feature_62 -1   2.3872524        73   65.07346  11.034653
28 + feature_40 -1   2.1111992        72   62.96226   9.736525
29 + feature_22 -1   2.0977092        71   60.86455   8.348066
30 + feature_35 -1   1.6032663        70   59.26128   7.678596
31 + feature_69 -1   1.5745139        69   57.68677   6.985761
32 + feature_26 -1   1.4251514        68   56.26162   6.484233
33  + feature_2 -1   1.1519636        67   55.10965   6.415468
34  + feature_3 -1   1.6335653        66   53.47609   5.406438
35 + feature_95 -1   1.1310246        65   52.34506   5.268742
36 + feature_83 -1   1.2547647        64   51.09030   4.842441
37 + feature_76 -1   1.6590202        63   49.43128   3.541317
38 + feature_56 -1   2.0518975        62   47.37938   1.301691
39 + feature_60 -1   2.5484669        61   44.83091  -2.227227
40 + feature_21 -1   1.4888581        60   43.34205  -3.604679
41 + feature_70 -1   1.3316650        59   42.01039  -4.725323
42 + feature_58 -1   1.7469753        58   40.26341  -6.972697
43 + feature_50 -1   1.5606009        57   38.70281  -8.925789
44 + feature_19 -1   1.3676468        56   37.33517 -10.523450
45 + feature_67 -1   2.1884708        55   35.14670 -14.563958
46 + feature_97 -1   0.9239254        54   34.22277 -15.227897
47 + feature_36 -1   0.7949873        53   33.42778 -15.578281
~~~
{: .output}



~~~
plot(coef(forward), beta[names(coef(forward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-5-1.png" title="plot of chunk unnamed-chunk-5" alt="plot of chunk unnamed-chunk-5" width="612" style="display: block; margin: auto;" />


~~~
## note about backward/both, not a challenge
all <- lm(y ~ . + 0, data = xy)
backward <- step(
    all,
    scope = formula(all),
    direction = "backward",
    trace = 0
)
backward$anova
~~~
{: .language-r}



~~~
          Step Df     Deviance Resid. Df Resid. Dev       AIC
1              NA           NA         1   1.718426 -208.3762
2 - feature_90  1 0.0008235507         2   1.719249 -210.3282
3 - feature_71  1 0.0016958853         3   1.720945 -212.2296
4 - feature_75  1 0.0061778362         4   1.727123 -213.8713
5 - feature_86  1 0.0012674407         5   1.728391 -215.7980
6 - feature_27  1 0.0161079808         6   1.744498 -216.8703
7  - feature_5  1 0.0252970300         7   1.769796 -217.4306
~~~
{: .output}



~~~
plot(coef(backward), beta[names(coef(backward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-6-1.png" title="plot of chunk unnamed-chunk-6" alt="plot of chunk unnamed-chunk-6" width="612" style="display: block; margin: auto;" />


{% include links.md %}
