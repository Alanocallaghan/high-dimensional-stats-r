---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 02-high-dimensional-regression_b.md in _episodes_rmd/
title: "Stepwise feature selection for regression"
teaching: 0
exercises: 0
questions:
- "Why would we want to find a subset of features
  that are associated with an outcome?"
- "How can we iteratively find a good subset of our features
  variables to use for regression?"
- "What are some risks and downsides of iterative feature
  selection?"
objectives:
- "Understand multiple regression in a biomedical context."
- "Understand how to fit a stepwise regression model."
keypoints:
- "Sets of features can be more predictive and provide
  a better explanation than a single feature alone."
- "Stepwise regression allows us to find a set of features that
  are associated with an outcome (eg, age)."
- "Stepwise regression will tend to retain only one
  feature out of many that are correlated."
- "Stepwise regression is not very efficient."
math: yes
---





In the previous 

Another way of modelling these data is to model age as 

$$
    y_j = \beta_0 + \beta_1 X_1 + \dots \beta_p X_p + \epsilon_j
$$



~~~
suppressPackageStartupMessages({
    library("glmnet")
    library("limma")
    library("minfi")
    library("here")
    library("broom")
})

if (!file.exists(here("data/methylation.rds"))) {
    source(here("data/methylation.R"))
}
norm <- readRDS(here("data/methylation.rds"))

lim <- norm
y <- lim$Age
X <- getM(lim)
~~~
{: .language-r}

However when the number of predictors is greater than the number of samples
(basically always true in genetics) it isn't possible to include everything!

There are some techniques that you can use to find a set of predictors!

- screening (correlation etc): bad, don't do
- screening (variance): not necessarily bad if the screening variable is sensible
- forward/reverse/best subset selection


~~~
if (!file.exists(here("data/synthetic.rds"))) {
    source(here("data/synthetic.R"))
}
synthetic <- readRDS(here("data/synthetic.rds"))
~~~
{: .language-r}





~~~
X <- assay(synthetic)
y <- synthetic$age
beta <- rowData(synthetic)$true_beta
names(beta) <- rownames(synthetic)
## challenge 3: fit y on x univariate
## compare with true betas
cc <- sapply(seq_len(nrow(X)), function(i) {
    coef(lm(y ~ X[i, ]))[[2]]
})
plot(cc, beta, pch = 19, cex = 0.5)
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-4-1.png" title="plot of chunk unnamed-chunk-4" alt="plot of chunk unnamed-chunk-4" width="612" style="display: block; margin: auto;" />




> ## Exercise
> Perform forward subset selection on the methylation data.
> 
> 
> > ## Solution
> > 
> > 
> {: .solution}
{: .challenge}




~~~
## challenge 4: forward selection
## compare with true betas
xy <- as.data.frame(cbind(t(X), y = y))
int <- lm(y ~ 1, data = xy)
all <- lm(y ~ . + 0, data = xy)
forward <- step(
    int,
    scope = list(upper = formula(all), lower = formula(int)),
    direction = "forward",
    trace = 0
)
forward$anova
~~~
{: .language-r}



~~~
           Step Df    Deviance Resid. Df Resid. Dev        AIC
1               NA          NA        99 1708.75000 285.834720
2  + feature_39 -1 499.4536126        98 1209.29639 253.262379
3  + feature_96 -1 324.0291081        97  885.26728 224.071942
4  + feature_12 -1 294.9334647        96  590.33381 185.551798
5  + feature_27 -1 207.3480230        95  382.98579 144.282770
6  + feature_62 -1  54.2795132        94  328.70628 130.999440
7  + feature_48 -1  52.0943130        93  276.61197 115.744549
8  + feature_34 -1  56.5924450        92  220.01952  94.854609
9  + feature_20 -1  61.8236485        91  158.19587  63.866377
10 + feature_59 -1  26.2910194        90  131.90485  47.691066
11 + feature_10 -1  11.0925496        89  120.81230  40.906794
12  + feature_4 -1  12.0358132        88  108.77649  32.412504
13 + feature_74 -1   8.7991872        87   99.97730  25.977300
14  + feature_1 -1   9.5964044        86   90.38090  17.886275
15 + feature_52 -1   5.5554267        85   84.82547  13.542568
16 + feature_47 -1   3.9651056        84   80.86037  10.755360
17 + feature_30 -1   5.4275720        83   75.43279   5.807193
18 + feature_60 -1   4.3717436        82   71.06105   1.836918
19 + feature_54 -1   3.8045694        81   67.25648  -1.665680
20 + feature_71 -1   2.9892313        80   64.26725  -4.212002
21 + feature_90 -1   2.9364471        79   61.33080  -6.888798
22 + feature_40 -1   2.5696161        78   58.76119  -9.168865
23  + feature_7 -1   2.4892286        77   56.27196 -11.497386
24 + feature_64 -1   1.7325691        76   54.53939 -12.624702
25  + feature_9 -1   1.9893105        75   52.55008 -14.340360
26 + feature_81 -1   1.5544502        74   50.99563 -15.343028
27 + feature_61 -1   1.9480462        73   49.04758 -17.237930
28 + feature_70 -1   1.7640150        72   47.28357 -18.900738
29 + feature_36 -1   1.4006782        71   45.88289 -19.907794
30 + feature_87 -1   1.3910210        70   44.49187 -20.986376
31 + feature_46 -1   1.4852141        69   43.00665 -22.381535
32 + feature_22 -1   1.4623565        68   41.54430 -23.840993
33 + feature_42 -1   1.3481457        67   40.19615 -25.139893
34 + feature_89 -1   1.3304489        66   38.86570 -26.505801
35 + feature_35 -1   1.1386274        65   37.72708 -27.479218
36  + feature_5 -1   1.6045366        64   36.12254 -29.825318
37 + feature_16 -1   0.9071641        63   35.21537 -30.368743
38 + feature_51 -1   0.9663070        62   34.24907 -31.151085
39 + feature_65 -1   1.5487561        61   32.70031 -33.778559
40 + feature_80 -1   1.0909933        60   31.60932 -35.171824
41 + feature_72 -1   1.5202071        59   30.08911 -38.100685
42 + feature_24 -1   0.7262915        58   29.36282 -38.544096
43 + feature_75 -1   0.8739263        57   28.48889 -39.565589
44 + feature_37 -1   0.7598234        56   27.72907 -40.268888
45  + feature_3 -1   0.9752670        55   26.75380 -41.849357
46 + feature_78 -1   1.3023538        54   25.45145 -44.839752
47 + feature_45 -1   0.7416338        53   24.70982 -45.796965
48 + feature_79 -1   0.6356983        52   24.07412 -46.403292
49 + feature_21 -1   0.4991660        51   23.57495 -46.498545
50 + feature_69 -1   0.5362969        50   23.03865 -46.799678
51 + feature_85 -1   0.4937631        49   22.54489 -46.966172
52 + feature_83 -1   0.4581378        48   22.08675 -47.019217
~~~
{: .output}



~~~
plot(coef(forward), beta[names(coef(forward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-5-1.png" title="plot of chunk unnamed-chunk-5" alt="plot of chunk unnamed-chunk-5" width="612" style="display: block; margin: auto;" />


~~~
## note about backward/both, not a challenge
all <- lm(y ~ . + 0, data = xy)
backward <- step(
    all,
    scope = formula(all),
    direction = "backward",
    trace = 0
)
backward$anova
~~~
{: .language-r}



~~~
          Step Df    Deviance Resid. Df Resid. Dev       AIC
1              NA          NA         1   4.060464 -122.3873
2 - feature_98  1 0.002594080         2   4.063058 -124.3234
3 - feature_45  1 0.004159458         3   4.067217 -126.2211
4 - feature_77  1 0.013398220         4   4.080616 -127.8922
~~~
{: .output}



~~~
plot(coef(backward), beta[names(coef(backward))])
abline(0, 1)
abline(v = 0, lty = "dashed", col = "firebrick")
abline(h = 0, lty = "dashed", col = "firebrick")
~~~
{: .language-r}

<img src="../fig/rmd-02b-unnamed-chunk-6-1.png" title="plot of chunk unnamed-chunk-6" alt="plot of chunk unnamed-chunk-6" width="612" style="display: block; margin: auto;" />


{% include links.md %}
